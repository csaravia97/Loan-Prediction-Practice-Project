{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function for making a classification model and accessing performance\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "    model.fit(data[predictors], data[outcome])    # Fit the model\n",
    "    \n",
    "    predictions = model.predict(data[predictors]) # Make predictions on training set\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(predictions, data[outcome])\n",
    "    print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "    \n",
    "    # Perform K-fold cross-val with 5 folds\n",
    "    kf = KFold(n_splits=5)\n",
    "    error = []\n",
    "    \n",
    "    for train, test in kf.split(data):\n",
    "        train_predictors = (data[predictors].iloc[train,:]) # training data\n",
    "        \n",
    "        train_target = data[outcome].iloc[train] # outcome of training data\n",
    "        \n",
    "        model.fit(train_predictors, train_target)\n",
    "        \n",
    "        error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test])) # Record error from each cross val run\n",
    "    \n",
    "    print(\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "    \n",
    "    #Fit the model again so that it can be refered outside the function:\n",
    "    model.fit(data[predictors],data[outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 81.374%\n",
      "Cross-Validation Score : 81.386%\n"
     ]
    }
   ],
   "source": [
    "outcome_var = 'Loan_Status'\n",
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "predictor_var = ['Credit_History']\n",
    "classification_model(model, df, predictor_var, outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just based off intuition you can guess that Credit History will be a big indicator for whether a person will be accepted for a loan or not. Our accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    378\n",
       "0    175\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Loan_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 81.374%\n",
      "Cross-Validation Score : 81.386%\n"
     ]
    }
   ],
   "source": [
    "predictor_var = ['Credit_History', 'Education', 'Married', 'Self_Employed', 'Property_Area']\n",
    "classification_model(model, df, predictor_var, outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite adding more features, our accuracy hasn't increased at all. This tells us that credit_history is being taken into account too much when deciding on whether to give out a loan. Let's try another model and see how it affects our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 81.374%\n",
      "Cross-Validation Score : 81.386%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "predictor_var = ['Credit_History','Gender','Married','Education']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite changing the models, the other categorical variables fail to outweigh the effects of Credit_History. Let's try running a model using the numerical variables along with Credit_History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 89.512%\n",
      "Cross-Validation Score : 69.980%\n"
     ]
    }
   ],
   "source": [
    "predictor_var = ['Credit_History','Loan_Amount_Term','LoanAmount_log']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Cross Validation Score is significantly lower than our accuracy, showing that we're probably overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n",
      "Cross-Validation Score : 70.357%\n"
     ]
    }
   ],
   "source": [
    "predictor_var = ['Credit_History','Loan_Amount_Term','LoanAmount_log', 'TotalIncome_log', 'Dependents']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're definitely overfitting here, let's try to reduce our features to only include the top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TotalIncome_log     0.389381\n",
       "Credit_History      0.308681\n",
       "LoanAmount_log      0.209864\n",
       "Dependents          0.046261\n",
       "Loan_Amount_Term    0.045813\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featimp = pd.Series(model.feature_importances_, index=predictor_var).sort_values(ascending=False)\n",
    "featimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n",
      "Cross-Validation Score : 72.531%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "predictor_var = ['Credit_History','TotalIncome_log', 'LoanAmount_log']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still overfitting, let's try to tune the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 85.895%\n",
      "Cross-Validation Score : 77.761%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth = 7, max_features = 3)\n",
    "predictor_var = ['Credit_History','TotalIncome_log', 'LoanAmount_log']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the parameters a little bit gets us a slightly better Cross Validation Score, let's try using a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.544%\n",
      "Cross-Validation Score : 81.201%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)\n",
    "predictor_var = ['TotalIncome_log','LoanAmount_log','Credit_History', 'Dependents', 'Property_Area']\n",
    "classification_model(model, df,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funnily enough, the Logistic Regression model using a single parameter is still giving us the best results. This tells me that I'd probably need to so some more in depth feature engineering to get a better score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df[['Credit_History']], df['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_lAUu6dG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "catergorical_vars = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n",
    "le = LabelEncoder()\n",
    "for i in catergorical_vars:\n",
    "    df_test[i] = le.fit_transform(df_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Loan_Status'] = model.predict(df_test[['Credit_History']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5720</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3076</td>\n",
       "      <td>1500</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1800</td>\n",
       "      <td>208.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001054</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2165</td>\n",
       "      <td>3422</td>\n",
       "      <td>152.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
       "0  LP001015       1        1           0          0              0   \n",
       "1  LP001022       1        1           1          0              0   \n",
       "2  LP001031       1        1           2          0              0   \n",
       "4  LP001051       1        0           0          1              0   \n",
       "5  LP001054       1        1           0          1              1   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5720                  0       110.0             360.0   \n",
       "1             3076               1500       126.0             360.0   \n",
       "2             5000               1800       208.0             360.0   \n",
       "4             3276                  0        78.0             360.0   \n",
       "5             2165               3422       152.0             360.0   \n",
       "\n",
       "   Credit_History  Property_Area  Loan_Status  \n",
       "0             1.0              2            1  \n",
       "1             1.0              2            1  \n",
       "2             1.0              2            1  \n",
       "4             1.0              2            1  \n",
       "5             1.0              2            1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using a more sophisticated model does not guarantee better results\n",
    "- It's not always wise to use blackbox models like the Random Forest without knowing how they work\n",
    "- Feature Engineering is a very important step and should not be overlooked\n",
    "- Since the  dataset was a bit skewed ( we had much more positive cases than negative cases) the cross-val accuracy predictor might've been misleading. For future reference I can look at the confusion matrix or the ROC curve to validate my results\n",
    "- Grid Search might help me in the future to decide how to handle null values and how to pick hyperparameters for my model.\n",
    "- Setting up a Pipeline of data cleaning steps will not only give me acces to a suite of data cleaning steps for future reference, but will also help me make sure that my data cleaning steps for my test set are the same as the ones for my training set. \n",
    "- Handling Categorical values using LabelEncoder may mess up on some models. If the categories aren't huge it may be better to use One Hot Encoding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
